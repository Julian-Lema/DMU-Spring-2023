{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5623c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DMUStudent.HW3: HW3, DenseGridWorld, visualize_tree\n",
    "using POMDPs: actions, @gen, isterminal, discount, statetype, actiontype, simulate, states, initialstate\n",
    "using D3Trees: inchrome\n",
    "using StaticArrays: SA\n",
    "using Statistics: mean, std, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81183ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab1444d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ":right"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############\n",
    "# Instructions\n",
    "##############\n",
    "#=\n",
    "\n",
    "This starter code is here to show examples of how to use the HW3 code that you\n",
    "can copy and paste into your homework code if you wish. It is not meant to be a\n",
    "fill-in-the blank skeleton code, so the structure of your final submission may\n",
    "differ from this considerably.\n",
    "\n",
    "Please make sure to update DMUStudent to gain access to the HW3 module.\n",
    "\n",
    "=#\n",
    "\n",
    "############\n",
    "# Question 2\n",
    "############\n",
    "\n",
    "\n",
    "mdp = HW3.DenseGridWorld(seed = 3)\n",
    "a = actions(mdp)\n",
    "s = states(mdp)\n",
    "policy_function = rand(actions(mdp))\n",
    "start_state = SA[19, 19]\n",
    "\n",
    "function rollout(mdp, start_state, max_steps=100)\n",
    "    r_total = 0.0\n",
    "    a = actions(mdp)\n",
    "    s = start_state\n",
    "    t = 0\n",
    "    while !isterminal(mdp, s) && t < max_steps\n",
    "        a = rand(actions(mdp))\n",
    "        s, r = @gen(:sp,:r)(mdp, s, a)\n",
    "        r_total += discount(mdp)^t*r\n",
    "        t += 1\n",
    "    end\n",
    "    return r_total # replace this with the reward\n",
    "end\n",
    "\n",
    "\n",
    "function heuristic_policy(s)\n",
    "    xtrue = s[1]\n",
    "    ytrue = s[2]\n",
    "    \n",
    "    x = mod(s[1],20)\n",
    "    y = mod(s[2],20)\n",
    "    \n",
    "    # If between bounds\n",
    "    if (20 - x > 10) & (20 - x != 20) \n",
    "        a = :left\n",
    "    elseif (20 - x <= 10) & (20 - x != 0)\n",
    "        a = :right\n",
    "    elseif 20 - y > 10\n",
    "        a = :down\n",
    "    else \n",
    "        a = :up\n",
    "    end\n",
    "    \n",
    "    # # If outside of internal square \n",
    "    # if 60 - xtrue > 40 \n",
    "    #     a = :right\n",
    "    # elseif 60 - xtrue < 20\n",
    "    #     a = :left \n",
    "    # elseif 60 - ytrue > 40\n",
    "    #     a = :up\n",
    "    # elseif 60 - ytrue < 20\n",
    "    #     a = :down\n",
    "    # else\n",
    "    #     return a\n",
    "    # end\n",
    "    \n",
    "    return a \n",
    "end\n",
    "\n",
    "\n",
    "function rollout_smart(mdp, start_state, heuristic_policy, max_steps=100)\n",
    "    r_total = 0.0\n",
    "    a = actions(mdp)\n",
    "    s = start_state\n",
    "    t = 0\n",
    "    while !isterminal(mdp, s) && t < max_steps\n",
    "        a = heuristic_policy(s)\n",
    "        s, r = @gen(:sp,:r)(mdp, s, a)\n",
    "        r_total += discount(mdp)^t*r\n",
    "        t += 1\n",
    "    end\n",
    "    return r_total # replace this with the reward\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "# # This code runs monte carlo simulations: you can calculate the mean and standard error from the results\n",
    "# results_random = [rollout(mdp, rand(initialstate(mdp))) for _ in 1:10000]\n",
    "# mean_random = mean(results_random)\n",
    "# SEM_random = std(results_random)/(length(results_random)^0.5)\n",
    "# @show mean_random\n",
    "# @show SEM_random\n",
    "\n",
    "# results_smart = [rollout_smart(mdp, rand(initialstate(mdp)), heuristic_policy) for _ in 1:10000]\n",
    "# mean_smart = mean(results_smart)\n",
    "# SEM_smart = std(results_smart)/(length(results_smart)^0.5)\n",
    "\n",
    "# @show mean_smart\n",
    "# @show SEM_smart\n",
    "\n",
    "# @show difference = mean_smart - mean_random\n",
    "\n",
    "heuristic_policy([19,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1b2908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typeof(s) = StaticArraysCore.SVector{2, Int64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DenseGridWorld()\n",
    "\n",
    "S = statetype(m)\n",
    "A = actiontype(m)\n",
    "\n",
    "# These would be appropriate containers for your Q, N, and t dictionaries:\n",
    "n = Dict{Tuple{S, A}, Int}()\n",
    "q = Dict{Tuple{S, A}, Float64}()\n",
    "t = Dict{Tuple{S, A, S}, Int}()\n",
    "\n",
    "# This is an example state - it is a StaticArrays.SVector{2, Int}\n",
    "s = SA[19,19]\n",
    "@show typeof(s)\n",
    "@assert s isa statetype(m)\n",
    "\n",
    "# here is an example of how to visualize a dummy tree (q, n, and t should actually be filled in your mcts code, but for this we fill it manually)\n",
    "q[(SA[1,1], :right)] = 0.0\n",
    "q[(SA[2,1], :right)] = 0.0\n",
    "n[(SA[1,1], :right)] = 1\n",
    "n[(SA[2,1], :right)] = 0\n",
    "t[(SA[1,1], :right, SA[2,1])] = 1\n",
    "\n",
    "q[[1,2],:right] = 1\n",
    "q[s,:right] = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "723b7806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdp = DenseGridWorld(seed=4)\n",
    "\n",
    "discount(mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cd6bd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mopen\u001b[24m \u001b[4m-a\u001b[24m \u001b[4m'Google Chrome'\u001b[24m \u001b[4m/var/folders/0g/ynx547mn6zqdsjcn17zrpwtc0000gn/T/jl_Zl7vXf/tree.html\u001b[24m`, ProcessExited(0))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "# Question 3\n",
    "############\n",
    "\n",
    "##########################################\n",
    "function rollout_smart(mdp, start_state, heuristic_policy, max_steps=100)\n",
    "    r_total = 0.0\n",
    "    a = actions(mdp)\n",
    "    s = start_state\n",
    "    t = 0\n",
    "    while !isterminal(mdp, s) && t < max_steps\n",
    "        a = heuristic_policy(s)\n",
    "        s, r = @gen(:sp,:r)(mdp, s, a)\n",
    "        r_total += discount(mdp)^t*r\n",
    "        t += 1\n",
    "    end\n",
    "    return r_total # replace this with the reward\n",
    "end\n",
    "##########################################\n",
    "function bonus(N, Ns, s, a)\n",
    "    \n",
    "    if N[(s,a)] == 0 || Ns == 0\n",
    "        return Inf\n",
    "    end    \n",
    "    \n",
    "    return sqrt(log(Ns)/N[(s,a)])  \n",
    "end\n",
    "\n",
    "\n",
    "##########################################\n",
    "\n",
    "function explore(mdp,N,s,Q,c)\n",
    "    A = actions(mdp)\n",
    "    Ns = sum(N[(s,a)] for a in A)\n",
    "    \n",
    "    index = argmax(Q[(s,a)] + c * bonus(N,Ns,s,a) for a in A)\n",
    "    return A[index] \n",
    "end\n",
    "\n",
    "##########################################\n",
    "function simulateMCTS(mdp,s,N,Q,d,c,V,T,discount)\n",
    "    A = actions(mdp)\n",
    "    \n",
    "    if d <= 0 \n",
    "        return rollout_smart(mdp, s, heuristic_policy), N, T, Q\n",
    "    end\n",
    "    \n",
    "    \n",
    "    if !haskey(N, (s,first(A)) )\n",
    "\n",
    "        for a in A\n",
    "            N[s,a] = 0\n",
    "            Q[s,a] = 0\n",
    "        end\n",
    "        return rollout_smart(mdp, s, heuristic_policy), N, T, Q\n",
    "    end\n",
    "    \n",
    "    a = explore(mdp,N,s,Q,c)\n",
    "    sprime , r = @gen(:sp,:r)(mdp,s,a)\n",
    "    \n",
    "    if !haskey(T, (s,a,sprime) )\n",
    "        T[s,a,sprime] = 0\n",
    "    end\n",
    "    \n",
    "    T[(s,a,sprime)] += 1\n",
    "    \n",
    "    q, N, T, Q = simulateMCTS(mdp,sprime,N,Q,d-1,c,V,T,discount)         \n",
    "    q = r + discount * q\n",
    "    \n",
    "    N[s,a] += 1\n",
    "    Q[s,a] += (q - Q[(s,a)]) / N[(s,a)]\n",
    "    return q, N, T, Q\n",
    "    \n",
    "end\n",
    "\n",
    "        \n",
    "##########################################\n",
    "function MCTS(mdp, reps)\n",
    "    s = SA[19,19]\n",
    "    dis = discount(mdp)\n",
    "    d = 15\n",
    "    c = 120\n",
    "    V = 0\n",
    "    S = statetype(mdp)\n",
    "    A = actiontype(mdp)\n",
    "    N = Dict{Tuple{S, A}, Int}()\n",
    "    Q = Dict{Tuple{S, A}, Float64}()\n",
    "    T = Dict{Tuple{S, A, S}, Int}()\n",
    "    A = actions(mdp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in 1:reps \n",
    "        q, N, T, Q = simulateMCTS(mdp,s,N,Q,d,c,V,T,dis)\n",
    "    end\n",
    "    \n",
    "\n",
    "    index = argmax(Q[s,a] for a in actions(mdp))\n",
    "        \n",
    "    return Q, N, T, A[index]\n",
    "\n",
    "end\n",
    "\n",
    "mdp = DenseGridWorld(seed=4)\n",
    "\n",
    "Q,N,T,A = MCTS(mdp, 7)\n",
    "\n",
    "\n",
    "\n",
    "inchrome(visualize_tree(Q, N, T, SA[19,19]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd969ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_random = -94.0215630004999\n",
      "SEM_random = 0.7691807144973255\n",
      "mean_smart = 10.812953195560723\n",
      "SEM_smart = 2.987935431305634\n",
      "difference = mean_smart - mean_random = 104.83451619606062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104.83451619606062"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "# Question 4\n",
    "############\n",
    "\n",
    "##########################################\n",
    "function rollout_smart(mdp, start_state, heuristic_policy, max_steps=100)\n",
    "    r_total = 0.0\n",
    "    a = actions(mdp)\n",
    "    s = start_state\n",
    "    t = 0\n",
    "    while !isterminal(mdp, s) && t < max_steps\n",
    "        a = heuristic_policy(s)\n",
    "        s, r = @gen(:sp,:r)(mdp, s, a)\n",
    "        r_total += discount(mdp)^t*r\n",
    "        t += 1\n",
    "    end\n",
    "    return r_total # replace this with the reward\n",
    "end\n",
    "\n",
    "##########################################\n",
    "function rollout_MCTS(mdp, start_state, max_steps=100)\n",
    "    r_total = 0.0\n",
    "    a = actions(mdp)\n",
    "    s = start_state\n",
    "    t = 0\n",
    "    while !isterminal(mdp, s) && t < max_steps\n",
    "        _,_,_,a = MCTS(mdp,s)\n",
    "        s, r = @gen(:sp,:r)(mdp, s, a)\n",
    "        r_total += discount(mdp)^t*r\n",
    "        t += 1\n",
    "    end\n",
    "    return r_total # replace this with the reward\n",
    "end\n",
    "##########################################\n",
    "function bonus(N, Ns, s, a)\n",
    "    \n",
    "    if N[(s,a)] == 0 || Ns == 0\n",
    "        return Inf\n",
    "    end    \n",
    "    \n",
    "    return sqrt(log(Ns)/N[(s,a)])  \n",
    "end\n",
    "\n",
    "\n",
    "##########################################\n",
    "\n",
    "function explore(mdp,N,s,Q,c)\n",
    "    A = actions(mdp)\n",
    "    Ns = sum(N[(s,a)] for a in A)\n",
    "    \n",
    "    index = argmax(Q[(s,a)] + c * bonus(N,Ns,s,a) for a in A)\n",
    "    return A[index] \n",
    "end\n",
    "\n",
    "##########################################\n",
    "function simulateMCTS(mdp,s,N,Q,d,c,V,T,discount)\n",
    "    A = actions(mdp)\n",
    "    \n",
    "    if d <= 0 \n",
    "        return rollout_smart(mdp, s, heuristic_policy), N, T, Q\n",
    "    end\n",
    "    \n",
    "    \n",
    "    if !haskey(N, (s,first(A)) )\n",
    "\n",
    "        for a in A\n",
    "            N[s,a] = 0\n",
    "            Q[s,a] = 0\n",
    "        end\n",
    "        return rollout_smart(mdp, s, heuristic_policy), N, T, Q\n",
    "    end\n",
    "    \n",
    "    a = explore(mdp,N,s,Q,c)\n",
    "    sprime , r = @gen(:sp,:r)(mdp,s,a)\n",
    "    \n",
    "    if !haskey(T, (s,a,sprime) )\n",
    "        T[s,a,sprime] = 0\n",
    "    end\n",
    "    \n",
    "    T[(s,a,sprime)] += 1\n",
    "    \n",
    "    q, N, T, Q = simulateMCTS(mdp,sprime,N,Q,d-1,c,V,T,discount)         \n",
    "    q = r + discount * q\n",
    "    \n",
    "    N[s,a] += 1\n",
    "    Q[s,a] += (q - Q[(s,a)]) / N[(s,a)]\n",
    "    return q, N, T, Q\n",
    "    \n",
    "end\n",
    "\n",
    "        \n",
    "##########################################\n",
    "function MCTS(mdp, s)\n",
    "    start = time_ns()\n",
    "    dis = discount(mdp)\n",
    "    d = 15\n",
    "    c = 120\n",
    "    V = 0\n",
    "    S = statetype(mdp)\n",
    "    A = actiontype(mdp)\n",
    "    N = Dict{Tuple{S, A}, Int}()\n",
    "    Q = Dict{Tuple{S, A}, Float64}()\n",
    "    T = Dict{Tuple{S, A, S}, Int}()\n",
    "    A = actions(mdp)\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    while time_ns() < start + 40_000_000 \n",
    "        q, N, T, Q = simulateMCTS(mdp,s,N,Q,d,c,V,T,dis)\n",
    "        count += 1\n",
    "    end\n",
    "    @show count\n",
    "\n",
    "    index = argmax(Q[s,a] for a in actions(mdp))\n",
    "        \n",
    "    return Q, N, T, A[index]\n",
    "\n",
    "end\n",
    "\n",
    "mdp = DenseGridWorld(seed=4)\n",
    "\n",
    "# Q,N,T,A = MCTS(mdp, 7)\n",
    "\n",
    "\n",
    "# This code runs monte carlo simulations: you can calculate the mean and standard error from the results\n",
    "results_random = [rollout(mdp, rand(initialstate(mdp))) for _ in 1:10000]\n",
    "mean_random = mean(results_random)\n",
    "SEM_random = std(results_random)/(length(results_random)^0.5)\n",
    "@show mean_random\n",
    "@show SEM_random\n",
    "\n",
    "results_smart = [rollout_MCTS(mdp, rand(initialstate(mdp))) for _ in 1:100]\n",
    "mean_smart = mean(results_smart)\n",
    "SEM_smart = std(results_smart)/(length(results_smart)^0.5)\n",
    "@show mean_smart\n",
    "@show SEM_smart\n",
    "\n",
    "\n",
    "@show difference = mean_smart - mean_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "22cfd7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:  43%|█████████████████▋                       |  ETA: 0:00:50\u001b[39m\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mWall clock time limit of 0.05 seconds for choosing an action online exceeded. Taking a random action.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ DMUStudent.HW3 none:14\u001b[39m\n",
      "\u001b[32mProgress:  46%|██████████████████▉                      |  ETA: 0:00:49\u001b[39m\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mWall clock time limit of 0.05 seconds for choosing an action online exceeded. Taking a random action.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ DMUStudent.HW3 none:14\u001b[39m\n",
      "\u001b[32mProgress:  56%|███████████████████████                  |  ETA: 0:00:41\u001b[39m\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mWall clock time limit of 0.05 seconds for choosing an action online exceeded. Taking a random action.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ DMUStudent.HW3 none:14\u001b[39m\n",
      "\u001b[32mProgress:  63%|█████████████████████████▉               |  ETA: 0:00:36\u001b[39m\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mWall clock time limit of 0.05 seconds for choosing an action online exceeded. Taking a random action.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ DMUStudent.HW3 none:14\u001b[39m\n",
      "\u001b[32mProgress:  76%|███████████████████████████████▏         |  ETA: 0:00:22\u001b[39m\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mWall clock time limit of 0.05 seconds for choosing an action online exceeded. Taking a random action.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ DMUStudent.HW3 none:14\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mWall clock time limit of 0.05 seconds for choosing an action online exceeded. Taking a random action.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ DMUStudent.HW3 none:14\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mWall clock time limit of 0.05 seconds for choosing an action online exceeded. Taking a random action.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ DMUStudent.HW3 none:14\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:32\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPlease submit results.json to gradescope.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(hw = 3.1, email = \"julian.lemabulliard@colorado.edu\", score = 64.0979875243398, hash = \"9af0b6fffe02df0f49171229946744317faf79bd2d421106e59e6206f41ea13d\")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############\n",
    "# Question 5\n",
    "############\n",
    "\n",
    "##########################################\n",
    "function rollout_smart(mdp, start_state, heuristic_policy, max_steps=100)\n",
    "    r_total = 0.0\n",
    "    a = actions(mdp)\n",
    "    s = start_state\n",
    "    t = 0\n",
    "    while !isterminal(mdp, s) && t < max_steps\n",
    "        a = heuristic_policy(s)\n",
    "        s, r = @gen(:sp,:r)(mdp, s, a)\n",
    "        r_total += discount(mdp)^t*r\n",
    "        t += 1\n",
    "    end\n",
    "    return r_total # replace this with the reward\n",
    "end\n",
    "\n",
    "##########################################\n",
    "function rollout_MCTS(mdp, start_state, max_steps=100)\n",
    "    r_total = 0.0\n",
    "    a = actions(mdp)\n",
    "    s = start_state\n",
    "    t = 0\n",
    "    while !isterminal(mdp, s) && t < max_steps\n",
    "        _,_,_,a = MCTS5(mdp,s)\n",
    "        s, r = @gen(:sp,:r)(mdp, s, a)\n",
    "        r_total += discount(mdp)^t*r\n",
    "        t += 1\n",
    "    end\n",
    "    return r_total \n",
    "end\n",
    "##########################################\n",
    "function bonus(N, Ns, s, a)\n",
    "    \n",
    "    if N[(s,a)] == 0 || Ns == 0\n",
    "        return Inf\n",
    "    end    \n",
    "    \n",
    "    return sqrt(log(Ns)/N[(s,a)])  \n",
    "end\n",
    "\n",
    "\n",
    "##########################################\n",
    "\n",
    "function explore(mdp,N,s,Q,c)\n",
    "    A = actions(mdp)\n",
    "    Ns = sum(N[(s,a)] for a in A)\n",
    "    \n",
    "    index = argmax(Q[(s,a)] + c * bonus(N,Ns,s,a) for a in A)\n",
    "    return A[index] \n",
    "end\n",
    "\n",
    "##########################################\n",
    "function simulateMCTS(mdp,s,N,Q,d,c,V,T,discount)\n",
    "    A = actions(mdp)\n",
    "    \n",
    "    if d <= 0 \n",
    "        return rollout_smart(mdp, s, heuristic_policy), N, T, Q\n",
    "    end\n",
    "    \n",
    "    \n",
    "    if !haskey(N, (s,first(A)) )\n",
    "\n",
    "        for a in A\n",
    "            N[s,a] = 0\n",
    "            Q[s,a] = 0\n",
    "        end\n",
    "        return rollout_smart(mdp, s, heuristic_policy), N, T, Q\n",
    "    end\n",
    "    \n",
    "    a = explore(mdp,N,s,Q,c)\n",
    "    sprime , r = @gen(:sp,:r)(mdp,s,a)\n",
    "    \n",
    "    if !haskey(T, (s,a,sprime) )\n",
    "        T[s,a,sprime] = 0\n",
    "    end\n",
    "    \n",
    "    T[(s,a,sprime)] += 1\n",
    "    \n",
    "    q, N, T, Q = simulateMCTS(mdp,sprime,N,Q,d-1,c,V,T,discount)         \n",
    "    q = r + discount * q\n",
    "    \n",
    "    N[s,a] += 1\n",
    "    Q[s,a] += (q - Q[(s,a)]) / N[(s,a)]\n",
    "    return q, N, T, Q\n",
    "    \n",
    "end\n",
    "\n",
    "        \n",
    "##########################################\n",
    "function MCTS5(mdp, s)\n",
    "    start = time_ns()\n",
    "    dis = discount(mdp)\n",
    "    d = 15\n",
    "    c = 120\n",
    "    V = 0\n",
    "    S = statetype(m)\n",
    "    A = actiontype(m)\n",
    "    N = Dict{Tuple{S, A}, Int}()\n",
    "    Q = Dict{Tuple{S, A}, Float64}()\n",
    "    T = Dict{Tuple{S, A, S}, Int}()\n",
    "    A = actions(mdp)\n",
    "    \n",
    "    \n",
    "    \n",
    "    while time_ns() < start + 40_000_000 \n",
    "        q, N, T, Q = simulateMCTS(mdp,s,N,Q,d,c,V,T,dis)\n",
    "    end\n",
    "    \n",
    "\n",
    "    index = argmax(Q[s,a] for a in actions(mdp))\n",
    "        \n",
    "    return A[index]\n",
    "\n",
    "end\n",
    "\n",
    "MCTS5(mdp,SA[5,5])\n",
    "\n",
    "HW3.evaluate(MCTS5, \"julian.lemabulliard@colorado.edu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b143d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
