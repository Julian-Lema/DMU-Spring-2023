{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5623c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DMUStudent.HW3: HW3, DenseGridWorld, visualize_tree\n",
    "using POMDPs: actions, @gen, isterminal, discount, statetype, actiontype, simulate, states, initialstate\n",
    "using D3Trees: inchrome\n",
    "using StaticArrays: SA\n",
    "using Statistics: mean, std, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81183ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1444d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_random = -94.22497936090735\n",
      "mean_smart = -18.60256773339322\n",
      "difference = mean_smart - mean_random = 75.62241162751414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.62241162751414"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############\n",
    "# Instructions\n",
    "##############\n",
    "#=\n",
    "\n",
    "This starter code is here to show examples of how to use the HW3 code that you\n",
    "can copy and paste into your homework code if you wish. It is not meant to be a\n",
    "fill-in-the blank skeleton code, so the structure of your final submission may\n",
    "differ from this considerably.\n",
    "\n",
    "Please make sure to update DMUStudent to gain access to the HW3 module.\n",
    "\n",
    "=#\n",
    "\n",
    "############\n",
    "# Question 2\n",
    "############\n",
    "\n",
    "\n",
    "mdp = HW3.DenseGridWorld(seed = 3)\n",
    "a = actions(mdp)\n",
    "s = states(mdp)\n",
    "policy_function = rand(actions(mdp))\n",
    "start_state = SA[19, 19]\n",
    "\n",
    "function rollout(mdp, start_state, max_steps=100)\n",
    "    r_total = 0.0\n",
    "    a = actions(mdp)\n",
    "    s = start_state\n",
    "    t = 0\n",
    "    while !isterminal(mdp, s) && t < max_steps\n",
    "        a = rand(actions(mdp))\n",
    "        s, r = @gen(:sp,:r)(mdp, s, a)\n",
    "        r_total += discount(mdp)^t*r\n",
    "        t += 1\n",
    "    end\n",
    "    return r_total # replace this with the reward\n",
    "end\n",
    "\n",
    "\n",
    "function heuristic_policy(s)\n",
    "    xtrue = s[1]\n",
    "    ytrue = s[2]\n",
    "    \n",
    "    x = mod(s[1],20)\n",
    "    y = mod(s[2],20)\n",
    "    \n",
    "    # If between bounds\n",
    "    if (20 - x > 10) & (20 - x != 20) \n",
    "        a = :left\n",
    "    elseif (20 - x <= 10) & (20 - x != 0)\n",
    "        a = :right\n",
    "    elseif 20 - y > 10\n",
    "        a = :down\n",
    "    else \n",
    "        a = :up\n",
    "    end\n",
    "    \n",
    "#     # If outside of internal square \n",
    "#     if 60 - xtrue > 40 \n",
    "#         a = :right\n",
    "#     elseif 60 - xtrue < 20\n",
    "#         a = :left \n",
    "#     elseif 60 - ytrue > 40\n",
    "#         a = :up\n",
    "#     elseif 60 - ytrue < 20\n",
    "#         a = :down\n",
    "#     else\n",
    "#         return a\n",
    "#     end\n",
    "    \n",
    "    return a \n",
    "end\n",
    "\n",
    "\n",
    "function rollout_smart(mdp, start_state, heuristic_policy, max_steps=100)\n",
    "    r_total = 0.0\n",
    "    a = actions(mdp)\n",
    "    s = start_state\n",
    "    t = 0\n",
    "    while !isterminal(mdp, s) && t < max_steps\n",
    "        a = heuristic_policy(s)\n",
    "        s, r = @gen(:sp,:r)(mdp, s, a)\n",
    "        r_total += discount(mdp)^t*r\n",
    "        t += 1\n",
    "    end\n",
    "    return r_total # replace this with the reward\n",
    "end\n",
    "\n",
    "# This code runs monte carlo simulations: you can calculate the mean and standard error from the results\n",
    "results_random = [rollout(mdp, rand(initialstate(mdp))) for _ in 1:10000]\n",
    "mean_random = mean(results_random)\n",
    "SEM_smart = std(results_random)/(length(results_random)^0.5)\n",
    "@show mean_random\n",
    "\n",
    "results_smart = [rollout_smart(mdp, rand(initialstate(mdp)), heuristic_policy) for _ in 1:10000]\n",
    "mean_smart = mean(results_smart)\n",
    "SEM_smart = std(results_smart)/(length(results_smart)^0.5)\n",
    "@show mean_smart\n",
    "\n",
    "@show difference = mean_smart - mean_random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca1b2908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typeof(s) = StaticArraysCore.SVector{2, Int64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DenseGridWorld()\n",
    "\n",
    "S = statetype(m)\n",
    "A = actiontype(m)\n",
    "\n",
    "# These would be appropriate containers for your Q, N, and t dictionaries:\n",
    "n = Dict{Tuple{S, A}, Int}()\n",
    "q = Dict{Tuple{S, A}, Float64}()\n",
    "t = Dict{Tuple{S, A, S}, Int}()\n",
    "\n",
    "# This is an example state - it is a StaticArrays.SVector{2, Int}\n",
    "s = SA[19,19]\n",
    "@show typeof(s)\n",
    "@assert s isa statetype(m)\n",
    "\n",
    "# here is an example of how to visualize a dummy tree (q, n, and t should actually be filled in your mcts code, but for this we fill it manually)\n",
    "q[(SA[1,1], :right)] = 0.0\n",
    "q[(SA[2,1], :right)] = 0.0\n",
    "n[(SA[1,1], :right)] = 1\n",
    "n[(SA[2,1], :right)] = 0\n",
    "t[(SA[1,1], :right, SA[2,1])] = 1\n",
    "\n",
    "q[[1,2],:right] = 1\n",
    "q[s,:right] = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cd6bd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q = 0\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching getindex(::Int64, ::Vector{Int64}, ::Symbol)\n\u001b[0mClosest candidates are:\n\u001b[0m  getindex(::Number) at number.jl:95\n\u001b[0m  getindex(::Union{AbstractChar, Number}, \u001b[91m::CartesianIndex{0}\u001b[39m) at multidimensional.jl:867\n\u001b[0m  getindex(::Number, \u001b[91m::Integer\u001b[39m) at number.jl:96\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching getindex(::Int64, ::Vector{Int64}, ::Symbol)\n\u001b[0mClosest candidates are:\n\u001b[0m  getindex(::Number) at number.jl:95\n\u001b[0m  getindex(::Union{AbstractChar, Number}, \u001b[91m::CartesianIndex{0}\u001b[39m) at multidimensional.jl:867\n\u001b[0m  getindex(::Number, \u001b[91m::Integer\u001b[39m) at number.jl:96\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] MCTS(mdp::DenseGridWorld, reps::Int64)",
      "   @ Main ./In[6]:76",
      " [2] top-level scope",
      "   @ In[6]:83"
     ]
    }
   ],
   "source": [
    "############\n",
    "# Question 3\n",
    "############\n",
    "\n",
    "\n",
    "\n",
    "# #struct MonteCarloTreeSearch\n",
    "# ð’« # problem\n",
    "# N # visit counts\n",
    "# Q # action value estimates\n",
    "# d # depth\n",
    "# m # number of simulations\n",
    "# c # exploration constant\n",
    "# U # value function estimate\n",
    "# end\n",
    "\n",
    "##########################################\n",
    "function bonus(N, Ns, s, a)\n",
    "    if N(s,a) == 0\n",
    "        return Inf\n",
    "    else \n",
    "        return sqrt(log(Ns)/N[s,a])\n",
    "    end    \n",
    "end\n",
    "\n",
    "\n",
    "##########################################\n",
    "\n",
    "function explore(mdp,a,s,q,c)\n",
    "    actions = actions(mdp)\n",
    "    Ns = sum(n[s,a] for a in actions)\n",
    "    \n",
    "    values, indices = findmax(q[s,a] + c * bonus(n[s,a],Ns,s,a))\n",
    "    return findmax(values)\n",
    "end\n",
    "\n",
    "##########################################\n",
    "function simulateMCTS(s,a,n,q,d,c,V)\n",
    "    if d <= 0 \n",
    "        return V = 0\n",
    "    end\n",
    "    \n",
    "    if !haskey(N, (s,first(a)) )\n",
    "        for a in a\n",
    "            n[s,a] = 0\n",
    "            q[s,a] = 0\n",
    "        end\n",
    "        V = findmax(q(s,a) + 0.9*t(s,a))\n",
    "    end\n",
    "    a = explore(mdp,a,s,Q,c)\n",
    "    sprime , r = @gen(:sp,:r)(mdp,s,a)\n",
    "    q = r + 0.9 * simulateMCTS(sprime,a,n,Q,d-1,n,c,V)\n",
    "    n[s,a] += 1\n",
    "    return q[s,a] += (q - q([s,a]))/n[(s,a)]\n",
    "    \n",
    "end\n",
    "\n",
    "        \n",
    "##########################################\n",
    "function MCTS(mdp, reps)\n",
    "    s = [19,19]\n",
    "    a = rand(actions(mdp))\n",
    "    d = 0\n",
    "    c = 0.8\n",
    "    V = 0\n",
    "    n = Dict{Tuple{S, A}, Int}()\n",
    "    q = Dict{Tuple{S, A}, Float64}()\n",
    "    t = Dict{Tuple{S, A, S}, Int}()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in reps \n",
    "        q = simulateMCTS(s,a,n,q,d,c,V)\n",
    "    end\n",
    "    @show q\n",
    "    values, idx = findmax(q[s,a]; dims = 2)[:]\n",
    "        \n",
    "    return findmax(values)\n",
    "\n",
    "end\n",
    "\n",
    "\n",
    "Q = MCTS(mdp,10)\n",
    "\n",
    "inchrome(visualize_tree(q, n, t, SA[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd969ca7",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: reducing over an empty collection is not allowed; consider supplying `init` to the reducer",
     "output_type": "error",
     "traceback": [
      "MethodError: reducing over an empty collection is not allowed; consider supplying `init` to the reducer",
      "",
      "Stacktrace:",
      "  [1] reduce_empty(op::Base.BottomRF{typeof(max)}, #unused#::Type{Float64})",
      "    @ Base ./reduce.jl:355",
      "  [2] reduce_empty_iter",
      "    @ ./reduce.jl:379 [inlined]",
      "  [3] reduce_empty_iter",
      "    @ ./reduce.jl:378 [inlined]",
      "  [4] foldl_impl",
      "    @ ./reduce.jl:49 [inlined]",
      "  [5] mapfoldl_impl",
      "    @ ./reduce.jl:44 [inlined]",
      "  [6] #mapfoldl#259",
      "    @ ./reduce.jl:170 [inlined]",
      "  [7] mapfoldl",
      "    @ ./reduce.jl:170 [inlined]",
      "  [8] #mapreduce#263",
      "    @ ./reduce.jl:302 [inlined]",
      "  [9] mapreduce",
      "    @ ./reduce.jl:302 [inlined]",
      " [10] #maximum#273",
      "    @ ./reduce.jl:757 [inlined]",
      " [11] maximum",
      "    @ ./reduce.jl:757 [inlined]",
      " [12] visualize_tree(q::Dict{Tuple{StaticArraysCore.SVector{2, Int64}, Symbol}, Float64}, n::Dict{Tuple{StaticArraysCore.SVector{2, Int64}, Symbol}, Int64}, t::Dict{Tuple{StaticArraysCore.SVector{2, Int64}, Symbol, StaticArraysCore.SVector{2, Int64}}, Int64}, root_state::StaticArraysCore.SVector{2, Int64}; title::String, init_expand::Int64, init_duration::Int64, kwargs::Base.Pairs{Symbol, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ DMUStudent.HW3 ~/.julia/packages/DMUStudent/kvfl2/src/hw3_tree_vis.jl:13",
      " [13] visualize_tree(q::Dict{Tuple{StaticArraysCore.SVector{2, Int64}, Symbol}, Float64}, n::Dict{Tuple{StaticArraysCore.SVector{2, Int64}, Symbol}, Int64}, t::Dict{Tuple{StaticArraysCore.SVector{2, Int64}, Symbol, StaticArraysCore.SVector{2, Int64}}, Int64}, root_state::StaticArraysCore.SVector{2, Int64})",
      "    @ DMUStudent.HW3 ~/.julia/packages/DMUStudent/kvfl2/src/hw3_tree_vis.jl:6",
      " [14] top-level scope",
      "    @ In[15]:114"
     ]
    }
   ],
   "source": [
    "mdp = DenseGridWorld(seed = 4)\n",
    "\n",
    "function bonus(N, Ns, s, a)\n",
    "    if N(s,a) == 0\n",
    "        return Inf\n",
    "    else \n",
    "        return sqrt(log(Ns)/N[s,a])\n",
    "    end    \n",
    "end\n",
    "\n",
    "function explore(mdp,a,s,q,n,c)\n",
    "    actions = actions(mdp)\n",
    "    Ns = sum(n[s,a] for a in actions)\n",
    "    values, indices = findmax(q[s,a] + c * bonus(n,n[s,a],s,a))\n",
    "    return actions[indices[rand(1:length(indices))]]\n",
    "end\n",
    "\n",
    "function simulateMCTS(mdp, s, a, q, n, t, d, c)\n",
    "    if d <= 0\n",
    "        return 0\n",
    "    end\n",
    "    \n",
    "    if !haskey(n, (s,a))\n",
    "        n[(s,a)] = 0\n",
    "        q[(s,a)] = 0\n",
    "        for sprime in states(mdp)\n",
    "            t[(s,a,sprime)] = 0\n",
    "        end\n",
    "        V = simulateMCTS(mdp, s, a, q, n, t, d, c)\n",
    "        q[(s,a)] = V\n",
    "        return V\n",
    "    end\n",
    "    \n",
    "    if n[(s,a)] == 0\n",
    "        V = rollout(mdp, s, a)\n",
    "        q[(s,a)] = V\n",
    "        n[(s,a)] += 1\n",
    "        return V\n",
    "    end\n",
    "    \n",
    "    if all(n[(s,b)] > 0 for b in actions(mdp))\n",
    "        b = explore(mdp, a, s, q, n, c)\n",
    "        sprime, r = @gen(:sp,:r)(mdp,s,b)\n",
    "        n[(s,b)] += 1\n",
    "        t[(s,a,sprime)] += 1\n",
    "        q[(s,a)] += (r + 0.9*simulateMCTS(mdp, sprime, b, q, n, t, d-1, c) - q[(s,a)]) / n[(s,a)]\n",
    "        return q[(s,a)]\n",
    "    else\n",
    "        b = rand(actions(mdp))\n",
    "        while n[(s,b)] > 0\n",
    "            b = rand(actions(mdp))\n",
    "        end\n",
    "        sprime, r = @gen(:sp,:r)(mdp,s,b)\n",
    "        n[(s,b)] += 1\n",
    "        t[(s,a,sprime)] += 1\n",
    "        q[(s,b)] = rollout(mdp, sprime, b)\n",
    "        q[(s,a)] += (r + 0.9*q[(s,b)] - q[(s,a)]) / n[(s,a)]\n",
    "        return q[(s,a)]\n",
    "    end\n",
    "end\n",
    "\n",
    "function MCTS(mdp, reps)\n",
    "    s = [19,19]\n",
    "    a = rand(actions(mdp))\n",
    "    d = 0\n",
    "    c = 0.8\n",
    "    V = 0\n",
    "    n = Dict{Tuple{S, A}, Int}()\n",
    "    q = Dict{Tuple{S, A}, Float64}()\n",
    "    t = Dict{Tuple{S, A, S}, Int}()\n",
    "    \n",
    "    for i in 1:reps\n",
    "        simulateMCTS(s,a,n,q,d,c,V)\n",
    "    end\n",
    "    \n",
    "    Q = Dict{Tuple{S,A},Float64}()\n",
    "    N = Dict{Tuple{S,A},Int}()\n",
    "    \n",
    "    for (sa, value) in q\n",
    "        s, a = sa\n",
    "        if haskey(n, sa)\n",
    "            N[sa] = n[sa]\n",
    "            if N[sa] > 0\n",
    "                Q[sa] = value / N[sa]\n",
    "            else\n",
    "                Q[sa] = 0\n",
    "            end\n",
    "        else\n",
    "            N[sa] = 0\n",
    "            Q[sa] = 0\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for (sa, value) in n\n",
    "        s, a = sa\n",
    "        if !haskey(N, sa)\n",
    "            N[sa] = value\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for s in states(mdp)\n",
    "        for a in actions(mdp)\n",
    "            if !haskey(t, (s,a,s))\n",
    "                t[(s,a,s)] = 0\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return Q, N, t\n",
    "end\n",
    "\n",
    "q , n , t = MCTS(mdp, 15)\n",
    "\n",
    "inchrome(visualize_tree(q, n, t, SA[19,19] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cfd7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# Question 4\n",
    "############\n",
    "\n",
    "# A starting point for the MCTS select_action function which can be used for Questions 3 and 4\n",
    "function select_action(m, s)\n",
    "\n",
    "    start = time_ns()\n",
    "    n = Dict{Tuple{statetype(m), actiontype(m)}, Int}()\n",
    "    q = Dict{Tuple{statetype(m), actiontype(m)}, Float64}()\n",
    "\n",
    "    while time_ns() < start + 40_000_000 # run for a maximum of 40 ms to leave 10 ms to select an action\n",
    "        break # replace this with mcts iterations to fill n and q\n",
    "    end\n",
    "\n",
    "    # select a good action based on q and/or n\n",
    "\n",
    "    return rand(actions(m)) # this dummy function returns a random action, but you should return your selected action\n",
    "end\n",
    "\n",
    "############\n",
    "# Question 4\n",
    "############\n",
    "\n",
    "HW3.evaluate(select_action, \"your.gradescope.email@colorado.edu\")\n",
    "\n",
    "# If you want to see roughly what's in the evaluate function (with the timing code removed), check sanitized_evaluate.jl\n",
    "\n",
    "########\n",
    "# Extras\n",
    "########\n",
    "\n",
    "# With a typical consumer operating system like Windows, OSX, or Linux, it is nearly impossible to ensure that your function *always* returns within 50ms. Do not worry if you get a few warnings about time exceeded.\n",
    "\n",
    "# You may wish to call select_action once or twice before submitting it to evaluate to make sure that all parts of the function are precompiled.\n",
    "\n",
    "# Instead of submitting a select_action function, you can alternatively submit a POMDPs.Solver object that will get 50ms of time to run solve(solver, m) to produce a POMDPs.Policy object that will be used for planning for each grid world. You can achieve a score of 50 without doing this, but this may give you an advantage if you want to maximize your score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
